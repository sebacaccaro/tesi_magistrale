In questo capitolo è descritta la metodologia di correzione.\\
Nella \autoref{sec:met_introduzione} vengono descritti gli obiettivi del processo di correzione e le criticità che lo contraddistinguono.
Nella \autoref{sec:met_panoramica} è presente una panoramica generale del processo di correzione. Sono inoltre descritte le fasi e le componenti del sistema. Nella \autoref{sec:met_BERT_MLM} è descritto il funzionamento del BERT Masked Language Model. Nelle sottosezioni \ref{sec:met_tok_correct} e \ref{sec:met_mod_split} è descritto il funzionamento dei moduli che stanno alla base del sistema di correzione.


\section{Introduzione}
\label{sec:met_introduzione}
L'Optical Character Recognition, o OCR, è una tecnologia tramite la quale è possibile estrarre e digitalizzare il testo presente in un'immagine. Più precisamente, "digitalizzare" significa tradurre il testo dell'immagine in una una codifica leggibile da una macchina, come ad esempio ASCII o Unicode.

\begin{figure}[H]
\centering
{
\begin{minipage}{0.4\textwidth}
\includegraphics[width=\textwidth]{immagini/metodologia/ocr_ex.png}
\end{minipage} \hfill
\begin{minipage}{0.06\textwidth}
\Large$\rightarrow$
\end{minipage}
\begin{minipage}{0.5\textwidth}
\footnotesize	
Prima. di dare la parola al primo iscritto, \\
mi permetto di far presente alla Camera che \\
sono già stati presentati vari ordini del giorno \\
e var.1 emendamenti, relativi a questo disegno \\
di legge. Come la Camera sa, gli emendamenti, \\
di regola, debbono esser presentati alrneno \\
ventiquattro ore prima della seduta in cui \\
vengono discussi.
\end{minipage}
\caption{A sinistra un frammento di immagine contenente testo, a destra il testo digitalizzato estratto dal frammento di immagine.}
\label{fig:met_ocr_esempio}
}
\end{figure}

L'uso di sistemi OCR è particolarmente vantaggioso per l'archiviazione dei documenti. Infatti, l'estrazione del testo rende possibile eseguire sui documenti operazioni di ricerca e di reperimento informazioni. Si pensi a un'operazione basilare come la ricerca di tutti i documenti che contengono una determinata parola: un task dispendioso e manuale che è quasi istantaneo se si ha a disposizione il testo digitalizzato.
\paragraph{Errori}
I sistemi OCR presentano però alcuni problemi che possono influenzare negativamente le performance nel reperimento di informazioni \cite{impatto_ocr_1}\cite{impatto_ocr_2}. Si veda, ad esempio, il testo estratto in \autoref{fig:met_ocr_esempio}: seppur la maggior parte delle parole sono state riconosciute correttamente, è possibile notare alcuni errori. 
Generalmente la presenza di tali errori è dovuta a piccole imprecisioni nell'immagine iniziale: si pensi ad esempio un granello di polvere che può essere scambiato per un punto, o ad una \textit{"n"} battuta male che viene scambiata per la sequenza \textit{"ii"}.
Si possono distinguere le seguenti categorie di errore:
\begin{itemize}
\item \textbf{Word Error}. Aggiunta, rimozione o sostituzione di caratteri spuri all'interno di una parola. Questo tipo di errore si divide in due ulteriori sottocategorie:
	\begin{itemize}
	\item Non-word error (NW): la parola affetta da errore non è presente in un dato vocabolario. Un errore di questo tipo è la parola \textit{"gioia"} che diventa \textit{"g1o1a"}.
	\item Real-word error (RW): la parola affetta da errore è presente in un dato vocabolario, ma non è corretta nella frase in cui è inserita. Ad esempio, la frase \textit{"qualvolta i popoli ripongono la loro fiducia  nelle \ul{armi} e nella guerra"} può essere erroneamente interpretata come \textit{"qualvolta i popoli ripongono la loro fiducia  nelle \ul{ami} e nella guerra"}. "ami" è una parola presente nel vocabolario, ma non è corretta nel contesto della frase data.
	\end{itemize}
	
\item \textbf{Word Segmentation Error}. Si ha un errore di segmentazione quando aggiunte, rimozioni o sostituzioni di caratteri (incluso il carattere spazio) occorrono in maniera tale da dividere o unire parole. Sono considerati errori di segmentazione anche aggiunte di caratteri e segni di punteggiatura spuri all'interno del testo. Sono distinte le seguenti sottocategorie di errori di segmentazione:
	\begin{itemize}
	\item Space Splitting (SP), quando i caratteri di una parola o più parole adiacenti sono intervallati da spaziature. Ad esempio, si ha un errore di questo tipo nella frase \textit{"vostra presenza conferma l'\ul{attaccamento alla} cattedra di Pietro e la fedeltà al suo Magistero"} che viene letta come \textit{"vostra presenza conferma l'\ul{a t t a c c a m e n t o a l l a} cattedra di Pietro e la fedeltà al suo Magistero"}.
	\item Punctuation Splitting (DP), quando uno o più segni di punteggiatura dividono in più parti una parola. Ad esempio, data la parola \textit{"attaccamento"} si ha un errore DP quando essa viene interpretata come \textit{"at,tacc,amento"}.
	\item Punctuation Insertion (PS), quando uno o più segni di punteggiatura vengono aggiunti fra una parola e l'altra. Ad esempio, data la frase \textit{"Per secoli la Chiesa ha patrocinato artisti che hanno..."}, si hanno errori PS quando essa viene interpretata come \textit{"Per \ul{secoli'la} Chiesa \ul{ha.,patrocinato} artisti che hanno..."}.
	\end{itemize}
\end{itemize}

In \autoref{tab:met_esempio_errori} sono riportati ulteriori esempi degli errori appena elencati.

\begin{table}[H]
\centering
\begin{tabular}{cccc}
\textbf{Originale} & \textbf{OCR} & \textbf{Tipo} & \textbf{Errore} \\ \hline
dell'impresa & dell’iinpresa 	& NW & Sostituzione di "m" con "in" \\
interessano & iateressano 		& NW & Sostituzione di "n" con "a" \\
questo modo & questo nodo 		& RW & Sostituzione di "m" con "n" \\
l'ingordizia & I’ingordizia 	& RW & Sostituzione di "l" con "I" \\
produttrice & pro d u t t rice 	& SP & Parola spezzettata da spazi \\
azionisti & azi:misti 			& DP & Sostituzione con divisione della parola \\
vicinanze  del & vicinanze .del & PS & Introduzione di punteggiatura\\

\end{tabular}
\caption{Esempi di errori}
\label{tab:met_esempio_errori}
\end{table}

Se, come già detto, gli errori derivano spesso da piccoli difetti nell'immagine di partenza, è lecito aspettarsi una maggior quantità di errori da documenti più deteriorati o datati, come archivi storici. Per lo stesso motivo l'intensità degli errori può variare, a seconda delle condizioni in parti diverse di uno documento.

\paragraph{OCR Post-processing}
Una strategia spesso adottata per minimizzare il numero di errori è l'aggiunta di
una fase di post elaborazione (OCR post-processing) in seguito all'acquisizione
dei documenti tramite OCR. Lo scopo della fase di OCR post-processing è quello di correggere gli errori introdotti durante l'estrazione del testo dalle immagini. Una delle difficoltà in questa fase sta nel non introdurre nuovi errori nel testo. Si pensi ai seguenti casi:
\begin{itemize}
\item Il sistema prova a correggere una parola che non contiene errori. In questo caso, qualsiasi correzione risulterà in un nuovo errore. Una delle maggiori criticità nello sviluppare il sistema di correzione, infatti, sta nell'identificare correttamente gli errori all'interno del testo.
\item Il sistema identifica correttamente un errore, ma propone una correzione sbagliata. Si pensi al seguente esempio: \textit{"vesodvi"} viene erroneamente corretto in \textit{"vedovi"}. Tuttavia, la parola originale era \textit{"vescovi"}.
\end{itemize}

\ \\
La metodologia di correzione sviluppata è modellata come una pipeline che si compone di una serie di moduli ripetibili in sequenza. Ogni modulo è una funzione che si occupa di individuare e correggere una specifica categoria di errore.\\
La metodologia sviluppata si propone di correggere gli errori di tipo RW e SP.

\section{Architettura del sistema}
\label{sec:met_processo}

\subsection{Panoramica Generale}
\label{sec:met_panoramica}
Il sistema di correzione è articolato come una pipeline composta da uno o più moduli 	concatenati. Un modulo è una funzione il cui scopo è correggere una specifica tipologia di errori all'interno di una frase. Un modulo può essere formalmente definito come segue:
\begin{equation}
M: F \mapsto F\prime
\end{equation}
dove $F$ e $F\prime$ sono rispettivamente la frase originale e quella con delle correzioni apportate. \\
Sono stati definiti i seguenti moduli:
\begin{itemize}
\item \textbf{Modulo di correzione Token} ($M_{TK}$): individua e corregge tutti gli errori di tipo RW. \E\ discusso in dettaglio nella \autoref{sec:met_tok_correct}.
\item \textbf{Modulo di correzione Split} ($M_{SP}$): individua e corregge tutti gli errori di tipo SP. \E\ discusso in dettaglio nella \autoref{sec:met_mod_split}.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{immagini/metodologia/modulo}
\caption{Schema del funzionamento di un modulo}
\label{fig:met_modulo}
\end{figure}

Come si può vedere in \autoref{fig:met_modulo}, il funzionamento di un modulo si compone delle fasi Error Detection (che da qui in poi sarà abbreviata con ED) ed Error Correction (che da qui in poi sarà abbreviata con EC). Durante la fase di ED vengono individuati gli errori presenti all'interno dalla frase da correggere: dato che moduli differenti correggono tipologie di errore differenti, ogni modulo applica una diversa strategia per individuare gli errori. Nella fase di EC vengono effettuate le correzioni degli errori individuati nella fase precedente.

\paragraph{Esempio} Si supponga di voler applicare alla seguente frase il modulo di correzione token:
\begin{center}
\textit{"\dashuline{Q o a l c h n} Papa \ul{nort} è compreso in questa comunità \ul{d1} morti \ul{gluriosi}"}
\end{center}
Il modulo di correzione token riconosce e corregge solo gli errori di tipo NW (Non-word error, sottolineati con linea continua), mentre ignora tutti gli errori di altro tipo (sottolineati con linea tratteggiata). L'output del modulo, supponendo di riuscire a correggere tutti gli errori, è il seguente:
\begin{center}
\textit{"\dashuline{Q o a l c h n} Papa non è compreso in questa comunità di morti gloriosi"}
\end{center}
\ \\
Data la definizione di modulo, è possibile definire una pipeline di correzione come una concatenazione di uno o più moduli. Più formalmente, una pipeline di correzione è definita come segue:
\begin{equation}
P: f_1 \circ f_2 \circ ... \circ f_n
\end{equation}
dove ogni $f_i$ è un modulo.
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{immagini/metodologia/generale}
\caption{Schema riassuntivo della pipeline di correzione}
\label{fig:met_generale}
\end{figure}

\paragraph{Esempio} Continuando l'esempio precedente, si supponga di concatenare un modulo $M_{SP}$ al precedente modulo $M_{TK}$. Il modulo riceve come input la frase con le correzioni apportate dal modulo precedente, e corregge tutti gli errori di tipo SP presenti nella frase (ovvero quelli con la sottolineatura tratteggiata):
\begin{center}
\textit{"Qualche Papa non è compreso in questa comunità di morti gloriosi"}
\end{center}



\ \\
All'interno della pipeline di correzione possono essere presenti più occorrenze di uno stesso modulo. In frasi con molti errori una sola applicazione di un dato modulo di correzione potrebbe non essere sufficiente per correggere tutti gli errori della propria tipologia. Per ragioni legate al funzionamento del BERT Masked Language Model che verranno meglio chiarite nelle prossime sottosezioni, infatti, ripetere un dato modulo più volte può aumentare tangibilmente le performance di correzione.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{immagini/metodologia/pipeline_esempio}
\caption{Esempio di una possibile pipeline con più occorrenze di uno stesso modulo}
\label{fig:met_pipeline_esempio}
\end{figure}




\subsection{BERT Masked Language Modeling}
\label{sec:met_BERT_MLM}
La fase di error correction di entrambi i moduli implementati fa uso del BERT Masked Language Modeling (da qui in poi riferito come BERT MLM). Data una qualsiasi sequenza $S = [w_1,...,w_n]$ nella quale ogni $w_i$ è una parola, è possibile mascherare una sola parola $w_i$ con la stringa \textit{[MASK]}. Si ottiene così la sequenza con maschera $S\prime = [w_1,...,\text{[MASK]},...,w_n]$.\\
Dando in input $S\prime$ al modello BERT, esso associa ad ogni parola del proprio lessico la probabilità di corrispondere la parola mascherata. Le prime n parole con la probabilità più alta sono dette candidati.
\E\ quindi formalizzata come segue la funzione del BERT MLM detta "mask-filling":
\begin{equation} \label{eq:met_BERT}
B: S\prime \rightarrow [c_1,...,c_n]
\end{equation}
dove ogni $c_i \in[c_1,...,c_n]$ è un candidato. 

\paragraph{Esempio} Data la frase 
\begin{center}
\textit{"che assistono ragazze in difficoltà, le persone \underline{soie} e abbandonate, gli ammalati e gli anziani."}
\end{center}
la parola \textit{"soie"} sottolineata è stata individuata come errore. \E\ quindi necessario mascherala, per dare la frase in input al modello BERT. La frase diventa dunque:
\begin{center}
\textit{"che assistono ragazze in difficoltà, le persone [MASK] e abbandonate, gli ammalati e gli anziani."}
\end{center}
BERT produce quindi una lista di candidati. Sono riportati i risultati impostando come soglia $n=5$. I candidati rappresentano le top-5 più probabili correzioni.
\begin{itemize}
\item \textit{"sole"} con probabilità 0.42
\item \textit{"anziane"} con probabilità 0.28
\item \textit{"povere"} con probabilità 0.08
\item \textit{"care"} con probabilità 0.03
\item \textit{"disabili"} con probabilità 0.01
\end{itemize}
\ \\
Bisogna sottolineare come la parola originale sia trasparente al modello BERT. Ciò significa che i candidati prodotti dal modello sono del tutto indipendenti dalla parola originale, e sono inferite unicamente dal contesto derivato dal resto della frase.\\




\subsection{Modulo di correzione Token}
\label{sec:met_tok_correct}

\subsubsection{Error Detection}
\label{sec:met_tok_errdet}
Il modulo di correzione token ha lo scopo di individuare e correggere tutti gli errori di tipo NW.  L'individuazione degli errori è effettuata in modo automatico dopo
una pre-elaborazione (pre-processing) del testo. Il funzionamento di questa
fase può quindi essere suddiviso in due stadi:

\begin{enumerate}
\item \textbf{Sentence pre-processing}: la frase viene tokenizzata, ovvero viene divisa singole parole dette token. Questo stadio è implementato tramite la libreria NLTK\cite{nltk}.
\item \textbf{Error marking}: ogni token è analizzato singolarmente per determinare se contenga o meno un errore. Un token è considerato errato se sono vere le seguente condizioni:
	\begin{itemize}
	\item Ha una lunghezza minima di 2 caratteri. Questa condizione è necessaria per evitare di introdurre nuovi errori correggendo inutilmente errori di tipo SP. Ad esempio, sarebbe deleterio provare a correggere le singole lettere di \textit{"Q u a l c h e"}. Ciò è dovuto al fatto che il modulo di correzione token è progettato per correggere singoli token: nell'esempio precedente, si tenterebbe quindi la correzione di tutte le sub-word che compongono il token. Per questo tipo di errori, è stato sviluppato di modulo di correzione Split (\autoref{sec:met_mod_split}).
	
	\item Dato un vocabolario di parole corrette, il token considerato non è presente in tale vocabolario. La ricerca nel vocabolario è eseguita in maniera case-insensitive. Tale approccio, seppur molto semplice ha alcune criticità. Ad esempio, ogni parola non appartenente alla lingua italiana verrà segnalata come errore. \E\ quindi auspicabile disporre di un vocabolario che comprenda anche alcune parole straniere di uso comune.
	\end{itemize}
Un'eccezione a quest'ultima condizione è data da tutti i token che precedono un apostrofo. Questi token sono considerati corretti se almeno una fra tutte le combinazioni token + vocale è corretta. Si prenda ad esempio il token \textit{"dell"} non presente nel vocabolario, seguito dal token apostrofo. Vengono generate le 5 combinazioni token-vocale \textit{"della"},\textit{"delle"},\textit{"delli"},\textit{"dello"},\textit{"dellu"}. Siccome almeno una di queste è corretta, il token è considerato corretto.
\end{enumerate}

Il processo appena descritto è schematizzato in \autoref{fig:met_tok_errdet}. Tutti gli errori identificati sono poi corretti in sequenza dalla fase di error correction. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{immagini/metodologia/error_detection}
\caption{Schema del processo di error detection}
\label{fig:met_tok_errdet}
\end{figure}

\subsubsection{Error Correction}
\label{sec:met_errcor}

La fase di error correction ha lo scopo di correggere gli errori individuati nella precedente fase. La fase di error correction è composta dai seguenti stadi:

\begin{enumerate}
\item Masking
\item Detokenization
\item Candidates generation and picking
\item Validation
\end{enumerate}

Ognuno di questi stadi è ripetuto per ognuno degli errori identificati durante la fase precedente.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{immagini/metodologia/tok_correction}
\caption{Schema della fase di error correction}
\label{fig:met_tok_correction}
\end{figure}



\paragraph{Masking}
Lo stadio di masking ha lo scopo di mascherare uno dei token errati individuati nella fase precedente. Si ricorda che, a causa del funzionamento del BERT MLM descritto nella \autoref{sec:met_BERT_MLM}, è possibile mascherare solo un token alla volta.\\
Data una sequenza di token $S = [t_1,...,t_n]$ e l'insieme $E = [t_i,t_j,...]\subseteq S$ dei token contenenti errore non ancora corretti, lo stadio di masking è descritto dalla seguente funzione:
\begin{equation}
M: S \rightarrow [t_1,...,\text{[MASK]},...,t_n] = S\prime
\end{equation}
dove \textit{[MASK]} sostituisce il primo token estratto dall'insieme $E$. Quanto descritto corrisponde al primo passaggio nella \autoref{fig:met_errgen}.


\paragraph{Detokenization}
Come spiegato nella \autoref{sec:met_BERT_MLM}, la funzione di mask-filling del BERT MLM richiede come input una sequenza intesa come frase, e non come insieme di token. \E\ quindi compito dello stadio di detokenization ricomporre una sequenza a partire dall'output dello stadio precedente. Lo stadio di detokenization è descritto dalla seguente funzione:
\begin{equation}
D: [t_1,...,\text{[MASK]},...,t_n] \rightarrow F_{mask}
\end{equation}
dove $F_{mask}$ è una frase contente una maschera.

\paragraph{Candidates generation and picking}
Lo stadio di candidates generation and picking sfrutta il BERT MLM per generare dei candidati per la correzione, e sfrutta un'euristica per determinare il candidato con la maggior probabilità di essere corretto (da qui in poi riferito come soluzione). Più precisamente, la generazione dei candidati avviene tramite la funzione di mask-filling descritta nell'\autoref{eq:met_BERT} (\autoref{sec:met_BERT_MLM}). La fattibilità di applicare tale approccio per la generazione di candidati per la correzione è dimostrata in \cite{OCRMaskFilling}. Nel paper appena citato si riporta come, usando una combinazione di BERT e FastText, la giusta correzione da applicare sia presente fra i candidati prodotti con una probabilità del 70\%. Risultati comparabili sono stati ottenuti con una metodologia simile dai test illustrati nella \autoref{sec:analisi}.\\
Lo step di generazione dei candidati è formalizzato come segue:
\begin{equation}
G: F_{mask} \rightarrow [c_1,...,c_n]= C
\end{equation}
dove ogni $c_i$ è un candidato.\\
L'euristica per la scelta della soluzione sceglie il candidato con la più bassa distanza di Levenshtein dal token mascherato. Più formalmente, chiamando $m$ il token mascherato, la soluzione $s$ è definita come segue:
\begin{equation}
s = \operatorname*{argmin}_{c_i \in C} d_{lev}(c_i,m)
\end{equation}
In caso uno o più candidati abbiano la stessa distanza dal token mascherato, viene scelto quello con la maggior probabilità prodotta da BERT. Questa euristica, seppur molto semplice, è decisamente efficace, come dimostrato dall'analisi nella \autoref{sec:ana_cor}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{immagini/metodologia/generazione_candidati}
\caption{Schema del processo di generazione e scelta dei candidati}
\label{fig:met_errgen}
\end{figure}

\paragraph{Validation}
Può accadere che la soluzione non sia una correzione adatta: si pensi ai seguenti casi:
\begin{enumerate}
\item L'error detection contrassegna un token corretto come errore. In questo caso, ogni tentativo di correzione introdurrebbe nuovi errori all'interno del testo.
\item BERT non produce la giusta correzione fra i candidati. Anche in questo caso, qualunque sia il candidato scelto, il sistema di correzione andrebbe a introdurre nuovi errori all'interno del testo.
\end{enumerate}

\E\ introdotta quindi un'ulteriore fase di validation, con lo scopo di valutare se la soluzione prodotta possa o meno rappresentare una correzione valida. La validazione è implementata tramite un'euristica che valuta se la soluzione trovata è troppo lontana (in termini di distanza di Levenshtein) dal token mascherato. Chiamando $l$ la lunghezza in caratteri del token mascherato, e $d$ la distanza di Levenshtein fra il token mascherato e la soluzione trovata, la soluzione è valida se:
\begin{itemize}
\item $l > 10 \wedge d < 5$ 
\item $l > 5 \wedge d < 4$ 
\item $l \leqslant 5 \wedge d < 3$ 
\end{itemize}
Se la validazione scarta la soluzione trovata il sistema ignora la correzione. Al contrario, se la validazione ritorna esito positivo, la correzione viene sostituita al token mascherato. Quanto appena descritto è rappresentato in \autoref{fig:met_pick}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{immagini/metodologia/scelta_candidati}
\caption{Schema del processo di scelta dei candidati}
\label{fig:met_pick}
\end{figure}
Il processo appena descritto si ripete per ogni errore contrassegnato durante la fase di error detection. Una volta completata la correzione dell'ultimo token errato, la fase di error correction può dirsi conclusa.

\subsubsection{Ripetizione}
In frasi contenenti molti errori, è possibile che una sola applicazione del modulo di correzione token non basti correggere tutti i non-word errors.\\
Ciò è dovuto al funzionamento di BERT, che usa il contesto a destra e sinistra della maschera per produrre i candidati di correzione. Se questo contesto è sporcato da molti errori, è più probabile che BERT non sia in grado di produrre una soluzione adeguata. \E\ quindi possibile che dopo l'applicazione di questo o altri moduli, e la conseguente correzione di alcuni errori, sia possibile ottenere migliori risultati sulle correzioni precedentemente non riuscite.\\
Questo approccio comporta però uno svantaggio: se la prima o una della prime correzioni sono sbagliate, il rischio è quello di introdurre rumore anche nelle correzioni successive.

\subsection{Modulo di correzione Split}
\label{sec:met_mod_split}

\subsubsection{Error detection}
\label{sec:met_split_errdet}
Il modulo di correzione Split corregge tutti gli errori di tipo SP.\\
La fase di error detection si compone di tre stadi:
\begin{enumerate}
\item \textbf{Sequences marking}: data un frase contenente errori di tipo SP, sono delimitati i punti di inizio e terminazione delle sequenze contenenti errori. L'individuazione di tali sequenze è eseguita tramite la seguente espressione regolare:
\begin{lstlisting}[language=Python]
r'(?:\s|^)(\w(?:\W?\s\w{1,2}){3,})(?:\W|\s|$)'
\end{lstlisting}
La precedente espressione regolare intercetta tutte le sequenze di almeno tre gruppi di caratteri alfanumerici con lunghezza massima due intervallati da spazi e/o caratteri non alfanumerici. Per maggiore chiarezza, in \autoref{table:met_split_esempi} sono riportati alcuni esempi di sequenze riconosciute.

\item \textbf{Punctuation filtering}: all'interno delle sequenze vengono rimossi tutti i caratteri non alfanumerici o spaziature. Ciò serve e rimuovere eventuali segni di punteggiatura spuri che possono diminuire l'efficacia delle seguenti fasi.

\item \textbf{Error validation:} non tutte le sequenze riconosciute dall'espressione regolare sono degli errori. Si pensi ad esempio ad una serie di preposizioni o congiunzioni, come il quarto esempio in \autoref{table:met_split_esempi}. Si usa quindi un'euristica per scartare le sequenze che si ritenga non contengano errori. Sono considerati errori tutte le sequenze nelle quali il numero di gruppi di 2 caratteri è minore del numero di gruppi di 1 carattere.

\end{enumerate}


\begin{table}[H]
	\centering
	\begin{tabular}{cccc}
	\textbf{\#} & \textbf{Frase} & \textbf{Sequenza} & \textbf{Errore} \\ \hline
	
	1 &\textit{"d i l e t t i membri, della ..."}	&	\textit{d i l e t t i}	&	Sì \\
	2 &\textit{"guidato d ui l l a fede"}			& 	\textit{d ui l l a}		&	Sì \\
	3 &\textit{"... altro tipo di u n i o, n e."}	&	\textit{u n i o, n e}	&	Sì \\
	4 &\textit{"in me e io in te, siano anch..."}	&	\textit{in me e io in te}&	No \\
	5 &\textit{"...dopo qu al ch e esitazione..."}	&	\textit{qu al ch e}&	Sì\\
	6 &\textit{"...dopo q u al che esitazione..."}	&	\textit{q u al}&	Sì\\
	7 &\textit{"...dopo qu al che esitazione..."}	&	/ &	/\\
	\end{tabular}
	\caption{Esempi di sequenze riconosciute}
	\label{table:met_split_esempi}
\end{table}
L'approccio di error correction appena esposto presenta però alcune limitazioni. Se uno dei gruppi della parola divisa contiene più di tre caratteri alfanumerici, la sequenza prodotta può:
\begin{itemize}
\item Non essere riconosciuta. \E\ il caso dell'esempio 7 nella \autoref{table:met_split_esempi}. In questo caso, il gruppo \textit{"che"} non è catturato dall'espressione regolare. Ciò comporta che il numero di gruppi di caratteri sia troppo basso per essere riconosciuto dall'espressione regolare.
\item Essere riconosciuta parzialmente.  \E\ il caso dell'esempio 6 nella \autoref{table:met_split_esempi}. In questo caso, il gruppo \textit{"che"} non è catturato dall'espressione regolare. Ciò comporta che venga catturata la sequenza \textit{"q u a l"}, che verrà corretta, introducendo possibilmente un errore. Il gruppo \textit{"che"}, invece, viene erroneamente considerato corretto.
\end{itemize}
\ \\
Data quindi una frase $f \in F$ contenente errori di segmentazione, dove $F$ è l'insieme di tutte le frasi, la fase di error detection è formalizzata come segue:
\begin{equation}
\textit{ED}_{split}: F \rightarrow L_{seq}
\end{equation}
dove ogni $l_{seq} \in L_{seq}$ è un insieme di tuple $[(s_1,b_1,e_1),...,(s_n,b_n,e_n)]$ nel quale ogni tupla corrisponde ad un errore individuato e validato. Ogni tupla è composta come segue:
\begin{itemize}
\item $s_i$ è la sequenza filtrata contenente l'errore
\item $b_i$ è il punto di inizio in $f$ della sequenza
\item $e_i$ è il punto di fine in $f$ delle sequenze
\end{itemize}

%\begin{figure}[H]
%\centering
%\includegraphics[width=\textwidth]{immagini/metodologia/split_error_detection}
%\caption{Schema del processo di error detection. Nell'immagine, ogni $c_i$ è un carattere}
%\label{fig:met_split_errdet}
%\end{figure}

\paragraph{Esempio}
Data la frase:
\begin{center}
\textit{coinvolsero ogni uomo \ul{e o' g n i} donna, \ul{p r o c u r a n d o}.}
\end{center}


\begin{table}[H]
\centering
\tabcolsep=0.16cm
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
0&1&2&3&4&5&6&7&8&9&10&11&12&13&14&15&16&17&18&19\\
\hline
c&o&i&n&v&o&l&s&e&r&o& &o&g&n&i& &u&o&m\\
\hline
\end{tabular}
\end{table}
\begin{table}[H]
\centering
\tabcolsep=0.11cm
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
20&21&22&23&24&25&26&27&28&29&30&31&32&33&34&35&36&37&38&39\\
\hline
o& &e& &o&'& &g& &n& &i& &d&o&n&n&a&,&\\
\hline
\end{tabular}
\end{table}
\begin{table}[H]
\centering
\tabcolsep=0.11cm
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
40&41&42&43&44&45&46&47&48&49&50&51&52&53&54&55&56&57&58&59\\
\hline
p& &r& &o& &c& &u& &r& &a& &n& &d& &o&.\\
\hline
\end{tabular}
\caption{Caratteri e indici delle frase esempio}
\end{table}




si procede con lo stadio di sequences marking. Le sequenze individuate sono quelle sottolineate nella frase data. Sono riportate di seguito insieme alla loro posizione di inizio e di fine.
\begin{table}[H]
\centering
\begin{tabular}{cccc}
\#&\textbf{Sequenza} & \textbf{Pos.Inizio} & \textbf{Pos.Fine}\\ \hline
1&\textit{"e o' g n i"}&22& 32\\
2&\textit{"p r o c u r a n d o"}& 40& 59\\
\end{tabular}
\end{table}

Si procede quindi con lo stadio di punctuation filtering:
\begin{table}[H]
\centering
\begin{tabular}{cccc}
\#&\textbf{Sequenza} & \textbf{Pos.Inizio} & \textbf{Pos.Fine}\\ \hline
1&\textit{"e o g n i"}&22& 32\\
2&\textit{"p r o c u r a n d o"}& 40& 59\\
\end{tabular}
\end{table}
Si noti come nella prima sequenza è stato cancellato un apostrofo, ma le posizioni di inizio e fine rimangono le stesse, in quanto demarcano l'inizio e la fine della sequenza nella frase originale. Lo stadio di error validation in questo caso non scarta alcuna soluzione: in entrambe le sequenze, infatti, il numero di gruppi di 1 carattere è maggiore del numero di gruppi di 2 caratteri.

\subsubsection{Error correction}
\label{sec:met_split_errcor}
La fase di Error Correction mira a correggere gli errori individuati nella fase precedente. Più formalmente è definita come:
\begin{equation}
EC_{split}: (F,L_{seq}) \rightarrow F_{corr}
\end{equation}
dove $F_{corr}$ è la frase con le correzione apportate.\\
La fase di Error Correction si compone dei seguenti stadi:
\begin{enumerate}
\item \textbf{Compression:} per ogni sequenza $s_i$ individuata da correggere, si rimuovono gli spazi bianchi, in modo da ottenere un'unica parola continua detta $s\prime_i$.
\item \textbf{Vocabulary correction}: se una sequenza $s\prime_i$ è presente nel vocabolario, allora è $s\prime_i$ viene inserita nella frase al posto della sequenza contenente l'errore.
\item \textbf{BERT correction:} si fa uso del BERT MLM per trovare una correzione, in modo simile a quanto fatto nel modulo di correzione token. A seconda della tipologia dell' errore sono applicabili due strategie di correzione.
		\begin{itemize}
		\item Con sottrazione		
		\item Con rimpiazzo		
		\end{itemize}
\end{enumerate}

Ognuno degli stadi appena descritti è applicato in sequenza ad ogni singola tupla prodotta dalla fase precedente.

\paragraph{Funzione di sostituzione}
Viene introdotta una funzione detta funzione di sostituzione. Data una frase $f \in F$, una sequenza $s \in S$, una valore di inizio $b \in I$ e un valore di fine $e \in E$, la funzione è definita come:
\begin{equation}
\textit{Sos}: (F,S,I,E) \rightarrow F\prime
\end{equation}
dove $F\prime$ è la frase $F$ in cui tutti i caratteri fra $b$ ed $e$ sono stati sostituiti da $s$.\\
Alternativamente, definendo come $T$ la tupla $(s,b,e)$ è possibile scrivere la funzione anche come segue:
\begin{equation}
\textit{Sos}: (F,T) \rightarrow F\prime
\end{equation}
Ad esempio, data la frase $f_{es}$:
\begin{center}
\textit{Onorando una trod1z1one plurisecolare}
\end{center}
e la tupla $t_{es}$ (\textit{"tradizione"},14,25), si ha che:
\begin{equation}
\textit{Sos}(f_{es},t_{es}) = \textit{Onorando una tradizione plurisecolare}
\end{equation}


\paragraph{Compression}
Lo stadio di compression rimuove gli spazi da ogni sequenza $s$ individuata come errore. Più formalmente, data una tupla $(s,b,e) \in T$ , lo stadio di compression è definito come segue:
\begin{equation}
\textit{Comp}: T \rightarrow T\prime
\end{equation}
dove in cui $T\prime$ è l'insieme di tutte le tuple $(s\prime,b,e)$ in cui $s\prime$ è la sequenza $s$ senza spaziature. Riprendendo l'esempio proposto nella fase di error detection, le tuple prodotte diventano rispettivamente:
\begin{table}[H]
\centering
\begin{tabular}{cccc}
\#&\textbf{Sequenza} & \textbf{Pos.Inizio} & \textbf{Pos.Fine}\\ \hline
1&\textit{"eogni"}&22& 32\\
2&\textit{"procurando"}& 40& 59\\
\end{tabular}
\end{table}

\paragraph{Vocabulary correction}
Date le tuple prodotte dallo stadio precedente, lo stadio di vocabulary correction applica una correzione per tutte le tuple la cui sequenza corrisponde ad una parola presente nel vocabolario. \\
Data quindi la frase $F$ contenente errori di segmentazione e una tupla $(s\prime,b,e)$ detta $t_{corr}$ che rispetta la condizione enunciata precedentemente, la frase con la correzione applicata $F_{corr}$ si ottiene come segue:
\begin{equation}
F_{corr} = \textit{Sos}(F,t_{corr})
\end{equation}
Se la tupla che si sta trattando può essere utilizzata per una correzione con vocabolario, la correzione si arresta in questo stadio. Altrimenti, si procede allo stadio di BERT correction.\\
Continuando l'esempio predente, si nota come la seconda tupla contenga la sequenza "procurando" che è una parola all'interno del vocabolario. Ricordando la frase originale
\begin{center}
\textit{coinvolsero ogni uomo e o' g n i donna, p r o c u r a n d o.}
\end{center}
detta $F_{ex}$, e la tupla $t_2$ (\textit{"procurando"}, 40, 59), la correzione si applica come segue:
\begin{equation}
F_{corr} = \textit{Sos}(F_{ex},t_{2})
\end{equation}
Il risulta è la frase $F_{corr}$:
\begin{center}
\textit{coinvolsero ogni uomo e o' g n i donna, procurando.}
\end{center}


\paragraph{BERT correction}
Per tutte le tuple per le quali non è stato possibile applicare una correzione con vocabolario, si passa allo stadio di BERT correction. Il primo step di questo stadio consiste nel mascheramento della sequenza errata nella fase originale. Data una tupla $(s\prime,b,e)$ prodotta dallo stadio di compressione e una frase $F$, si ottiene la frase mascherata $F_{mask}$ come segue:
\begin{equation}
F_{mask} = \textit{Sos}(F,\textit{[MASK]},b,e)
\end{equation}
A questo punto si sfrutta il BERT MLM per produrre un candidato per la correzione. Il processo è analogo alla fase di generazione e scelta dei candidati del modulo di correzione token nella \autoref{sec:met_errcor}, per cui si rimanda il lettore al paragrafo che ne spiega il funzionamento.\\
Una volta prodotto il candidato per la correzione, detto $c_{corr}$, è possibile applicare una correzione per sottrazione o per rimpiazzo.


\paragraph{Correzione con sottrazione}
Si applica in caso $c_{corr}$ coincida con la fine o l'inizio della sequenza compressa $s\prime$. Questo è il caso in cui la sequenza riconosciuta come errore di spezzettamento con spazi comprende due parole. Pertanto, se $c_{corr}$ corrisponde all'inizio di $s\prime$, si ottengono le due stringhe $\textit{sub}_1$ e $\textit{sub}_2$ come segue:
\begin{equation}
\textit{sub}_1,\textit{sub}_2 = c_{corr}, s\prime -c_{corr}
\end{equation}
Se invece $c_{corr}$ corrisponde alla fine di $s\prime$, le stringhe $\textit{sub}_1$ e $\textit{sub}_2$ si ottengono  come segue:
\begin{equation}
\textit{sub}_1,\textit{sub}_2 = s\prime -c_{corr},c_{corr},
\end{equation}
Data quindi la frase $F$ contenente errori di segmentazione, la tupla $(s\prime,b,e)$ e le stringhe $\textit{sub}_1,\textit{sub}_2$, la frase con la correzione applicata $F_{corr}$ si ottiene come segue:
\begin{equation}
F_{corr} = \textit{Sos}(F, \textit{sub}_1 + "\ " + \textit{sub}_2  ,b,e)
\end{equation}
La correzione con sottrazione corregge i casi in cui la sequenza contenente errore è formata da due parole. Può accadere che la stringa $s\prime -c_{corr}$ non rappresenti una parola corretta, ovvero potrebbe non essere presente nel vocabolario. Non sono previsti controlli e contromisure ad hoc per tale eventualità: la correzione di eventuali errori di questo tipo è delegata ai moduli di correzione token che possono essere inseriti a valle nella pipeline.\\
Si consideri ora l'esempio portato avanti negli stadi precedenti: data la tupla $t_2$ (\textit{"eogni"}, 22, 32) e la frase $F_{ex}$
\begin{center}
\textit{coinvolsero ogni uomo e o' g n i donna, p r o c u r a n d o.}
\end{center}
si ottiene come la frase $F_{mask}$ applicando la funzione di sostituzione:
\begin{equation}
F_{mask} = \textit{Sos}(F_{ex},\textit{[MASK]},22,32)
\end{equation}
Si ottiene dunque la frase
\begin{center}
\textit{coinvolsero ogni uomo [MASK] donna, p r o c u r a n d o.}
\end{center}
Sfruttando il BERT MLM si ottiene il candidato $c_{corr}$ "ogni". Il candidato corrisponde alla fine di $s\prime$, pertanto si ottengono $\textit{sub}_1,\textit{sub}_2 = \textit{e}, \textit{ogni}$. Si applica quindi la funzione di sostituzione:
\begin{equation}
F_{corr} = \textit{Sos}(F_{ex}, \textit{e} + "\ " + \textit{ogni} ,22,32)
\end{equation}
La frase corretta $F_{corr}$ è quindi: 
\begin{center}
\textit{coinvolsero ogni uomo e ogni donna, p r o c u r a n d o.}
\end{center}

\paragraph{Correzione con rimpiazzo}
Si applica in caso $c_{corr}$ non coincida con la fine o l'inizio della sequenza compressa $s\prime$. Questo step utilizza un'euristica per validare la correzione prodotta dal BERT MLM. La soluzione prodotta da BERT è valutata ammissibile e solo se $d_{lev}(s\prime,c_{corr}) \leqslant 4$.\\
In caso la soluzione sia ammissibile, la correzione è applicata tramite la funzione di sostituzione:
\begin{equation}
F_{corr} = \textit{Sos}(F,c_{corr},b,r)
\end{equation}
In caso la soluzione non sia ammissibile, la correzione si arresta senza apportare correzioni.


















