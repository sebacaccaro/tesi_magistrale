Ad oggi, sempre più libri cartacei, riviste e giornali presenti in biblioteche e archivi storici stanno venendo trasformati in versioni elettroniche che possono essere manipolate da un computer. A questo scopo, nel corso degli anni sono state sviluppate tecnologie di Optical Character Recognition (comunemente abbreviato con OCR) per tradurre le scansioni e immagini di documenti testuali in testo interpretabile e processabile da un computer. Questi sistemi, però, non sono perfetti e possono introdurre errori nel testo, che possono abbassare drasticamente la precisione di vari task di NLP. In questa tesi si propone un approccio modulare per la correzione di tali errori basato su BERT, un modello di machine learing finalizzato al NLP rilasciato da Google nel 2018. L'approccio proposto è valutato su un dataset creato ad hoc, contenente testi con diverse tipologie e intensità di errore.  I risultati sperimentali dimostrano la fattibilità di utilizzare approcci basati su BERT per la correzione di errori in testi acquisiti tramite OCR, mostrando inoltre come ci siano ulteriori margini per migliorare l'approccio proposto.