In questa tesi è stato sviluppato e proposto un approccio automatico al problema dell'OCR post processing, basato sull'uso di un modello BERT pre-allenato. Sono state definite una metodologia di test e delle metriche apposite per valutare le performance del sistema sviluppato. Data la difficoltà nel trovare un dataset con sequenze parallele di testo acquisito tramite OCR e testo corretto, è stato sviluppato un sistema per introdurre in maniera controllata rumore in sequenze di testo pulite. Ciò ha consentito di ottenere un dataset su cui è stato possibile eseguire i test stabiliti. I risultati ottenuti mostrano come il sistema sviluppato, a seconda del livello di rumore presente all'interno del testo, riesca a correggere fra il 25\% e il 40\% degli errori presenti, a fronte di una minima quantità di errori introdotti. \E\ stata infine eseguita un'analisi sulle prestazioni del sistema, che ha permesso di individuarne le maggiori criticità per eventuali sviluppi futuri.\\
Il lavoro svolto in questa tesi dimostra come l'utilizzo di un modello BERT pre-allenato sia un approccio percorribile per il problema dell'OCR post-processing, sebbene l'analisi dell'errore dimostri come il sistema sviluppato abbia ampi margini di miglioramento.

\paragraph{Sviluppi futuri} I risultati dei test e l'analisi dell'errore nei capitoli \ref{sec:test} e \ref{sec:analisi} fanno emergere alcune aree in cui è possibile migliorare il sistema sviluppato:

\begin{itemize}
\item I test hanno dimostrato come all'aumentare della lunghezza del testo in input il sistema produca risultati migliori. Potrebbe quindi essere opportuno usare frasi di 256 caratteri (limite superiore per BERT) e portare avanti la correzione con un approccio a sliding window sul testo. Questo approccio avrebbe il vantaggio di massimizzare la lunghezza delle frasi e di eseguire automaticamente più iterazioni su errori non corretti. Sarebbe però necessario un nuovo metodo per valutare le prestazioni del sistema su segmenti di testo più lunghi.

\item L'analisi dell'errore ha dimostrato come la parte di error correction del sistema agisca correttamente almeno nel 70\% (nel caso del tipo di frase con performance peggiori). Il sistema di correzione, nel migliore dei casi, corregge il 40\% degli errori presenti. Buona parte di questo scarto può essere attribuibile alla fase di error detection, che andrebbe riscritta rimpiazzando l'attuale sistema che fa semplicemente uso di un vocabolario.

\item I test fanno emergere come il sistema di correzione non abbia ottime performance sui word segmetation error. Sarebbe quindi opportuno esplorare altre soluzioni per questo tipo di errori. In questo ambito, l'analisi della letteratura suggerisce come approcci basati su NMT possano ottenere buoni risultati (\autoref{sec:arte_nmt}).
\end{itemize}